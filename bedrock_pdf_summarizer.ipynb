{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e507fcc7",
   "metadata": {},
   "source": [
    "# ðŸ“„ Amazon Bedrock + LangChain PDF Summarizer Demo\n",
    "This notebook demonstrates how to summarize a PDF file using Amazon Bedrock with Claude and LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c1e31ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from langchain_aws.llms.bedrock import BedrockLLM\n",
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.docstore.document import Document\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "758e22af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONFIGURATION ---\n",
    "BEDROCK_REGION = \"us-east-1\"\n",
    "MODEL_ID = \"anthropic.claude-v2\"\n",
    "\n",
    "# --- INIT BEDROCK CLIENT ---\n",
    "boto3_bedrock = boto3.client(\"bedrock-runtime\", region_name=BEDROCK_REGION)\n",
    "llm = BedrockLLM(model_id=MODEL_ID, client=boto3_bedrock)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "758a4c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- FUNCTION: Load PDF and Extract Text ---\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    with open(pdf_path, \"rb\") as f:\n",
    "        reader = PyPDF2.PdfReader(f)\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text[:4000]  # Limit token length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed85d628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- LOAD PDF ---\n",
    "pdf_path = \"sample1.pdf\"\n",
    "raw_text = extract_text_from_pdf(pdf_path)\n",
    "document = Document(page_content=raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e7aa5c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PROMPT TEMPLATE ---\n",
    "prompt_template = \"\"\"Summarize the following content professionally:\n",
    "\n",
    "{text}\n",
    "\n",
    "Summary:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "chain = load_summarize_chain(llm, chain_type=\"stuff\", prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6fd1dc21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“„ Document Summary (Bullet Points):\n",
      "\n",
      "â€¢ Here is a professional summary of the key points from the report:\n",
      "\n",
      "The 2025 State of Tech Talent Report examines the impact of artificial intelligence (AI) on the technology workforce.\n",
      "â€¢ Key findings include:\n",
      "\n",
      "- Critical talent gaps exist across organizations, with 68% understaffed in AI/ML, 65% in cybersecurity, and 61% in FinOps.\n",
      "â€¢ - 67% of organizations report AI is reshaping technical roles, requiring upskilling of the workforce.\n",
      "â€¢ - With high turnover, organizations face substantial recruiting and onboarding costs.\n",
      "â€¢ Open source culture boosts retention.\n",
      "â€¢ - 85% prioritize practical work portfolios and open source contributions in hiring, evidencing skills.\n",
      "â€¢ - 94% expect AI to deliver value, increasing the need for skilled workers.\n",
      "â€¢ Upskilling is 3.2x more likely than external hiring.\n",
      "â€¢ - Certifications are considered important by 71% when recruiting.\n",
      "â€¢ Upskilling takes 62% less time than hiring and onboarding.\n",
      "â€¢ - 2.7x more organizations expanded rather than reduced staff due to AI, intensifying the talent shortage.\n",
      "â€¢ The report highlights AI's net positive workforce impact but urgent need to reskill workers to fill critical gaps.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def simple_sent_tokenize(text):\n",
    "    # Splits sentences by ., !, or ? followed by a space or end of line\n",
    "    return [s.strip() for s in re.split(r'(?<=[.!?])\\s+', text) if s.strip()]\n",
    "\n",
    "# --- RUN SUMMARY ---\n",
    "summary = chain.invoke([document])  # Your existing summarisation call\n",
    "\n",
    "if isinstance(summary, dict) and 'output_text' in summary:\n",
    "    print(\"\\nðŸ“„ Document Summary (Bullet Points):\\n\")\n",
    "\n",
    "    raw_text = summary['output_text']\n",
    "    sentences = simple_sent_tokenize(raw_text)\n",
    "\n",
    "    for sentence in sentences:\n",
    "        print(f\"â€¢ {sentence}\")\n",
    "else:\n",
    "    print(\"\\nðŸ“„ Unexpected Output:\\n\")\n",
    "    print(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4780205",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "b3fa666e89899ffbc47f7502a00482b0c7c2c43bb0c452c379c940e92ddb7e77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
